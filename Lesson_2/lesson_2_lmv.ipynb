{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I8YmY3j6o7d"
      },
      "source": [
        "### 1. Создание признакового пространства "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcwsA3TK6o7e"
      },
      "source": [
        "Алгоритмы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо конвертировать текст в наборы цифр (векторы). Это называется извлечением признаков.\n",
        "\n",
        "##### Мешок слов\n",
        "– это популярная и простая техника извлечения признаков, используемая при работе с текстом. Она описывает вхождения каждого слова в текст.\n",
        "\n",
        "Чтобы использовать модель, нам нужно:\n",
        "\n",
        "- Определить словарь известных слов (токенов).\n",
        "- Выбрать степень присутствия известных слов.\n",
        "\n",
        "Любая информация о порядке или структуре слов игнорируется. Вот почему это называется МЕШКОМ слов. Эта модель пытается понять, встречается ли знакомое слово в документе, но не знает, где именно оно встречается.\n",
        "\n",
        "Интуиция подсказывает, что схожие документы имеют схожее содержимое. Также, благодаря содержимому, мы можем узнать кое-что о смысле документа.\n",
        "\n",
        "Пример:\n",
        "Рассмотрим шаги создания этой модели. Мы используем только 4 предложения, чтобы понять, как работает модель. В реальной жизни вы столкнетесь с бОльшими объемами данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BzFZXXDT6o7f"
      },
      "outputs": [],
      "source": [
        "documents = [\"I like this movie, it's it's it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1y2nAAfZ6o7g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krXvAy2A6o7i"
      },
      "source": [
        "Определяем словарь и создаем векторы документа. Соберем все уникальные слова из 4 загруженных предложений, игнорируя регистр, пунктуацию и односимвольные токены. Это и будет наш словарь (известные слова).\n",
        "\n",
        "Для создания словаря можно использовать класс CountVectorizer из библиотеки sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-mOc5xkD6o7i"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spC6BKto6o7j",
        "outputId": "35ef90ef-dba4-451e-e425-fd5d0942ded8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I like this movie, it's it's it's funny.\",\n",
              " 'I hate this movie.',\n",
              " 'This was awesome! I like it.',\n",
              " 'Nice one. I love it.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "5SYVU-7t6o7j",
        "outputId": "b5d7b5ac-7366-4346-c959-645ec49092ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   awesome  funny  hate  it  like  love  movie  nice  one  this  was\n",
              "0        0      1     0   3     1     0      1     0    0     1    0\n",
              "1        0      0     1   0     0     0      1     0    0     1    0\n",
              "2        1      0     0   1     1     0      0     0    0     1    1\n",
              "3        0      0     0   1     0     1      0     1    1     0    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d98cd350-eb0d-4dee-b986-4ecb89d934a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awesome</th>\n",
              "      <th>funny</th>\n",
              "      <th>hate</th>\n",
              "      <th>it</th>\n",
              "      <th>like</th>\n",
              "      <th>love</th>\n",
              "      <th>movie</th>\n",
              "      <th>nice</th>\n",
              "      <th>one</th>\n",
              "      <th>this</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98cd350-eb0d-4dee-b986-4ecb89d934a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d98cd350-eb0d-4dee-b986-4ecb89d934a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d98cd350-eb0d-4dee-b986-4ecb89d934a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "count_vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word', binary=False,)\n",
        "\n",
        "# Создаем the Bag-of-Words модель\n",
        "bag_of_words = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Отобразим Bag-of-Words модель как DataFrame\n",
        "feature_names = count_vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu7-3tww6o7k"
      },
      "source": [
        "Когда размер словаря увеличивается, вектор документа тоже растет. В примере выше, длина вектора равна количеству известных слов.\n",
        "\n",
        "В некоторых случаях, у нас может быть неимоверно большой объем данных и тогда вектор может состоять из тысяч или миллионов элементов. Более того, каждый документ может содержать лишь малую часть слов из словаря.\n",
        "\n",
        "Как следствие, в векторном представлении будет много нулей. Векторы с большим количеством нулей называются разреженным векторами (sparse vectors), они требуют больше памяти и вычислительных ресурсов. Частично эту проблему можно реить хорошей предобработкой.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LADh18hd6o7k"
      },
      "source": [
        "##### Мешок N-грамм\n",
        "\n",
        "Другой, более сложный способ создания словаря – использовать сгруппированные слова. Это изменит размер словаря и даст мешку слов больше деталей о документе. Такой подход называется «N-грамма».\n",
        "\n",
        "N-грамма это последовательность каких-либо сущностей (слов, букв, чисел, цифр и т.д.). В контексте языковых корпусов, под N-граммой обычно понимают последовательность слов. Юниграмма это одно слово, биграмма это последовательность двух слов, триграмма – три слова и так далее. Цифра N обозначает, сколько сгруппированных слов входит в N-грамму. В модель попадают не все возможные N-граммы, а только те, что фигурируют в корпусе.\n",
        "\n",
        "Пример:\n",
        "Рассмотрим такое предложение:The office building is open today\n",
        "\n",
        "Вот его биграммы:\n",
        "\n",
        "- the office\n",
        "- office building\n",
        "- building is\n",
        "- is open\n",
        "- open today\n",
        "\n",
        "Как видно, мешок биграмм – это более действенный подход, чем мешок слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "1CYHTMK56o7l",
        "outputId": "7218b041-89a6-45ad-8faf-db6c03c9c969"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9f4c1236f4fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\"I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0muy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BPE' is not defined"
          ]
        }
      ],
      "source": [
        "BPE\n",
        "\"I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.\"\n",
        "\n",
        "nn - t1\n",
        "uy - t2\n",
        "t1u - t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcahQq0A6o7m",
        "outputId": "9a705ca9-6b58-432a-fc0f-7f141f042f5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'like'),\n",
              " ('like', 'this'),\n",
              " ('this', 'movie,'),\n",
              " ('movie,', \"it's\"),\n",
              " (\"it's\", 'funny.'),\n",
              " ('funny.', 'I'),\n",
              " ('I', 'hate'),\n",
              " ('hate', 'this'),\n",
              " ('this', 'movie.'),\n",
              " ('movie.', 'This'),\n",
              " ('This', 'was'),\n",
              " ('was', 'awesome!'),\n",
              " ('awesome!', 'I'),\n",
              " ('I', 'like'),\n",
              " ('like', 'it.'),\n",
              " ('it.', 'Nice'),\n",
              " ('Nice', 'one.'),\n",
              " ('one.', 'I'),\n",
              " ('I', 'love'),\n",
              " ('love', 'it.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "text = \"I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.\"\n",
        "tokenized = text.split()\n",
        "bigrams = ngrams(tokenized, 2)\n",
        "list(bigrams)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYtZpbmk6o7m"
      },
      "source": [
        "##### TF-IDF\n",
        "\n",
        "У частотного скоринга есть проблема: слова с наибольшей частотностью имеют, соответственно, наибольшую оценку. В этих словах может быть не так много информационного выигрыша для модели, как в менее частых словах. Один из способов исправить ситуацию – понижать оценку слова, которое часто встречается во всех схожих документах. Это называется TF-IDF.\n",
        "\n",
        "TF-IDF (сокращение от term frequency — inverse document frequency) – это статистическая мера для оценки важности слова в документе, который является частью коллекции или корпуса.\n",
        "\n",
        "Скоринг по TF-IDF растет пропорционально частоте появления слова в документе, но это компенсируется количеством документов, содержащих это слово."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ4Yw8Id6o7n"
      },
      "source": [
        "<img src='image/tf_idf.PNG'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "rfi23FCU6o7n",
        "outputId": "937986d1-a113-4345-9ca2-1e333a783a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    awesome     funny      hate        it      like      love     movie  \\\n",
              "0  0.000000  0.397864  0.000000  0.761854  0.313681  0.000000  0.313681   \n",
              "1  0.000000  0.000000  0.702035  0.000000  0.000000  0.000000  0.553492   \n",
              "2  0.539445  0.000000  0.000000  0.344321  0.425305  0.000000  0.000000   \n",
              "3  0.000000  0.000000  0.000000  0.345783  0.000000  0.541736  0.000000   \n",
              "\n",
              "       nice       one      this       was  \n",
              "0  0.000000  0.000000  0.253951  0.000000  \n",
              "1  0.000000  0.000000  0.448100  0.000000  \n",
              "2  0.000000  0.000000  0.344321  0.539445  \n",
              "3  0.541736  0.541736  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a5d1c46-987f-4b24-88bb-6258f724c96b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>awesome</th>\n",
              "      <th>funny</th>\n",
              "      <th>hate</th>\n",
              "      <th>it</th>\n",
              "      <th>like</th>\n",
              "      <th>love</th>\n",
              "      <th>movie</th>\n",
              "      <th>nice</th>\n",
              "      <th>one</th>\n",
              "      <th>this</th>\n",
              "      <th>was</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.397864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.313681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.253951</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.702035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.448100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.539445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.344321</td>\n",
              "      <td>0.425305</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.344321</td>\n",
              "      <td>0.539445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.541736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a5d1c46-987f-4b24-88bb-6258f724c96b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a5d1c46-987f-4b24-88bb-6258f724c96b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a5d1c46-987f-4b24-88bb-6258f724c96b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "document = [\"I like this movie, it's funny funny.\",\n",
        "            'I hate this movie.', \n",
        "            'This was awesome! I like it.', \n",
        "            'Nice one. I love it.']\n",
        "\n",
        "\n",
        "document =  [\"I like this movie, it's it's it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "values = tfidf_vectorizer.fit_transform(document)\n",
        "\n",
        "# Show the Model as a pandas DataFrame\n",
        "feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pd.DataFrame(values.toarray(), columns = feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiXqXksk6o7o",
        "outputId": "dfe97d8f-d181-4b75-d072-b3d1c2c0474d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.91629073, 1.91629073, 1.91629073, 1.22314355, 1.51082562,\n",
              "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.22314355,\n",
              "       1.91629073])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tfidf_vectorizer.idf_"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dL-kqJB_FNIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPBpK3K6o7o"
      },
      "source": [
        "##### HashingVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXEz0XIz6o7p"
      },
      "source": [
        "Подсчеты и частоты могут быть очень полезны, но одним из ограничений этих методов является то, что словарный запас может стать очень большим. Это, в свою очередь, потребует больших векторов для кодирования документов и налагает большие требования к памяти и замедляет алгоритмы.\n",
        "\n",
        "Умный обходной путь - использовать односторонний хэш слов, чтобы преобразовать их в целые числа. Умная часть заключается в том, что словарь не требуется, и вы можете выбрать произвольный длинный вектор фиксированной длины. Недостатком является то, что хеш является односторонней функцией, поэтому нет способа преобразовать кодировку обратно в слово (что может не иметь значения для многих контролируемых задач обучения).HashingVectorizer класс реализует этот подход, который можно использовать для последовательного хеширования слов, а затем для токенизации и кодирования документов по мере необходимости.\n",
        "\n",
        "Пример ниже демонстрирует HashingVectorizer для кодирования одного документа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKUUAPoa6o7p"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "document = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n",
        "vectorizer = HashingVectorizer(n_features=2**4,)\n",
        "values = vectorizer.fit_transform(document)\n",
        "print(values.shape)\n",
        "print(values.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54CQckL6o7p"
      },
      "source": [
        "Выполнение примера кодирует образец документа как разреженный массив из 16 элементов. Значения закодированного документа соответствуют нормализованному количеству слов по умолчанию в диапазоне от -1 до 1, но могут быть сделаны простые целочисленные счетчики путем изменения конфигурации по умолчанию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jhlduv66o7q"
      },
      "source": [
        "##### Для чего нужны Vectorizers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jryg3ce06o7q"
      },
      "source": [
        "Алгоритмы машинного обучения не могут напрямую работать с сырым текстом, поэтому необходимо конвертировать текст в наборы цифр (векторы). Уже с векторным представлением можно производить классификацию, к примеру."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "91dV49BW6o7r",
        "outputId": "8c475c6c-e7f9-46e7-8a57-18436cec709c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text       label\n",
              "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
              "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
              "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
              "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
              "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d9ad779-a74d-4ea4-a136-a23bed3b5874\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d9ad779-a74d-4ea4-a136-a23bed3b5874')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d9ad779-a74d-4ea4-a136-a23bed3b5874 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d9ad779-a74d-4ea4-a136-a23bed3b5874');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Загружаем данные\n",
        "data = open('corpus').read()\n",
        "labels, texts = [], []\n",
        "for i, line in enumerate(data.split(\"\\n\")):\n",
        "    content = line.split()\n",
        "    labels.append(content[0])\n",
        "    texts.append(\" \".join(content[1:]))\n",
        "\n",
        "# создаем df\n",
        "trainDF = pd.DataFrame()\n",
        "trainDF['text'] = texts\n",
        "trainDF['label'] = labels\n",
        "trainDF.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "s5gaUe4e6o7r"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMraujJN6o7r",
        "outputId": "6857f541-344a-45e3-f9c0-50667611663f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "linear_model.LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgHn_9Xn6o7s",
        "outputId": "b4f4b139-6d1f-408e-c15e-1c0b11f1f6fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8644"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.transform(valid_y)\n",
        "\n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(trainDF['text'])\n",
        "\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)\n",
        "\n",
        "classifier = linear_model.LogisticRegression()\n",
        "classifier.fit(xtrain_count, train_y)\n",
        "predictions = classifier.predict(xvalid_count)\n",
        "#predictions\n",
        "accuracy_score(valid_y, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.transform(valid_y)\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "count_vect = HashingVectorizer(n_features=200)\n",
        "count_vect.fit(trainDF['text'])\n",
        "\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)\n",
        "\n",
        "classifier = linear_model.LogisticRegression()\n",
        "classifier.fit(xtrain_count, train_y)\n",
        "predictions = classifier.predict(xvalid_count)\n",
        "#predictions\n",
        "accuracy_score(valid_y, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4YUjs3xHeiz",
        "outputId": "55306089-ad1e-4155-cd83-eac53dfefc9d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7068"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.transform(valid_y)\n",
        "\n",
        "\n",
        "count_vect = TfidfVectorizer()\n",
        "\n",
        "count_vect.fit(trainDF['text'])\n",
        "\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)\n",
        "\n",
        "classifier = linear_model.LogisticRegression()\n",
        "classifier.fit(xtrain_count, train_y)\n",
        "predictions = classifier.predict(xvalid_count)\n",
        "#predictions\n",
        "accuracy_score(valid_y, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO4HcjcyIDLZ",
        "outputId": "cd9334e0-4bb5-48ac-c5bd-526736de1356"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8684"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cKzhaVmJ6o7s"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvwddpCT6o7s",
        "outputId": "8a560cc5-ddb5-4e2b-d067-0a2d376e727d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8688"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "accuracy_score(valid_y, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgJNP4ch6o7t",
        "outputId": "18fa3e2e-4ce0-4f72-d8a5-4013da2f8d9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__label__1    5097\n",
              "__label__2    4903\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "trainDF['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3sskeWL6o7t"
      },
      "source": [
        "### Векторные представления слов (word embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebcWS83Y6o7t"
      },
      "source": [
        "Векторное представление слова (word embedding) — вещественный вектор в пространстве с фиксированной невысокой размерностью.\n",
        "\n",
        "                                            Пример векторных представлений слов (2D t-SNE)\n",
        "<img src='image/2D_tsne.PNG'>\n",
        "\n",
        "Зачем нужны Word embeddings?\n",
        "Сжатые векторные представления слов\n",
        "1. полезны сами по себе, например, для поиска\n",
        "синонимов или опечаток в поисковых запросах.\n",
        "2. используются в качестве признаков для решения\n",
        "самых различных задач: выявление именованных сущностей, тэгирование частей речи, машинный перевод, кластеризация документов, ранжирование документов, анализ тональности текста."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVpvfB2v6o7t"
      },
      "source": [
        "#### word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyx6Fr3L6o7u"
      },
      "source": [
        "Мера семантической близости — мера близости, предназначенная для количественной оценки семантической схожести слов. Такая мера показывает высокие значения для пар слов, находящихся в семантических отношениях (синонимия, ассоциативность и т.д.), и нулевые значения для всех остальных пар.\n",
        "\n",
        "word2vec - алгоритм для получения векторных представлений слов. Подход основан на важной гипотезе, которую в науке принято называть гипотезой локальности — “слова, которые встречаются в одинаковых окружениях, имеют близкие значения”. Близость в данном случае понимается очень широко, как то, что рядом могут стоять только сочетающиеся слова. Например, для нас привычно словосочетание \"заводной будильник\". А сказать “заводной апельсин” мы не можем* — эти слова не сочетаются.\n",
        "\n",
        "##### Алгоритм word2vec\n",
        "Мы будем предсказывать вероятность слова по его окружению (контексту). То есть мы будем учить такие вектора слов, чтобы вероятность, присваиваемая моделью слову была близка к вероятности встретить это слово в этом окружении в реальном тексте.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0lY_gYM6o7u"
      },
      "source": [
        "<img src='image/w2v_formula.PNG'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuA_VUdd6o7u"
      },
      "source": [
        "Здесь W0 — вектор целевого слова, Wc — это некоторый вектор контекста, вычисленный (например, путем усреднения) из векторов окружающих нужное слово других слов. А S — это функция, которая двум векторам сопоставляет одно число. Например, это может быть косинусное расстояние.\n",
        "\n",
        "Процесс тренировки устроен следующим образом: мы берем последовательно (2k+1) слов, слово в центре является тем словом, которое должно быть предсказано. А окружающие слова являются контекстом длины по k с каждой стороны. Каждому слову в нашей модели сопоставлен уникальный вектор, который мы меняем в процессе обучения нашей модели. В целом, этот подход называется CBOW — continuous bag of words, continuous потому, что мы скармливаем нашей модели последовательно наборы слов из текста, a BoW потому что порядок слов в контексте не важен.\n",
        "<img src='image/CBOW_.png'>\n",
        "Другой подход skip-gram — прямо противоположный CBOW, то есть “словосочетание с пропуском”. Мы пытаемся из данного нам слова угадать его контекст (точнее вектор контекста). В остальном модель не претерпевает изменений.\n",
        "<img src='image/skipgram.png'>\n",
        "\n",
        "Что стоит отметить: хотя в модель не заложено явно никакой семантики, а только статистические свойства корпусов текстов, оказывается, что натренированная модель word2vec может улавливать некоторые семантические свойства слов. Классический пример:\n",
        "\n",
        "<img src='image/word_embeddings.PNG'>\n",
        "\n",
        "Слово \"мужчина\" относится к слову \"женщина\" так же, как слово \"дядя\" к слову \"тётя\", что для нас совершенно естественно и понятно, но в других моделям добиться такого же соотношения векторов можно только с помощью специальных ухищрений. Здесь же — это происходит естественно из самого корпуса текстов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZesZQyJ6o7u"
      },
      "source": [
        "#### Что мы можем попробовать сделать с векторами слов?\n",
        "\n",
        "Мы можем делать различные синтаксические, семантические NLP задачи с векторами слов, некоторое из них уже встроены. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEZ1NzeM6o7v"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "vMv8tTvX6o7v"
      },
      "outputs": [],
      "source": [
        "api.info()['models'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ley7PmgZ6o7v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cTjkSTk6o7v"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # загрузим предтренированные вектора слов из gensim-data\n",
        "# выведим слово наиболее близкое к 'woman', 'king' и далекое от 'man'\n",
        "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
        "print(\"{}: {:.4f}\".format(*result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3JY-iNG6o7v"
      },
      "outputs": [],
      "source": [
        "# выведем лишнее слово\n",
        "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
        "\n",
        "print(word_vectors.doesnt_match(\"black green summer brown\".split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2KmQ4TW6o7w"
      },
      "outputs": [],
      "source": [
        "# определим схожесть между словами\n",
        "similarity = word_vectors.similarity('woman', 'man')\n",
        "print(similarity)\n",
        "\n",
        "similarity = word_vectors.similarity('human', 'man')\n",
        "print(similarity)\n",
        "\n",
        "similarity = word_vectors.similarity('bee', 'man')\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPefn3ya6o7w"
      },
      "outputs": [],
      "source": [
        "# найдем top-3 самых близких слов\n",
        "result = word_vectors.similar_by_word(\"man\", topn=3)\n",
        "print(result)\n",
        "\n",
        "result = word_vectors.similar_by_word(\"cat\", topn=3)\n",
        "print(result)\n",
        "\n",
        "result = word_vectors.similar_by_word(\"mouth\", topn=3)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvWUocQ16o7w"
      },
      "source": [
        "# Simple chat-bot example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEbdsbcV6o7w"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "import annoy\n",
        "from gensim.models import Word2Vec, FastText\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYVo_XhE6o7x"
      },
      "outputs": [],
      "source": [
        "assert True\n",
        "\n",
        "#Small preprocess of the answers\n",
        "\n",
        "question = None\n",
        "written = False\n",
        "\n",
        "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
        "    with open(\"Otvety.txt\", \"r\") as fin:\n",
        "        for line in tqdm_notebook(fin):\n",
        "            if line.startswith(\"---\"):\n",
        "                written = False\n",
        "                continue\n",
        "            if not written and question is not None:\n",
        "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
        "                written = True\n",
        "                question = None\n",
        "                continue\n",
        "            if not written:\n",
        "                question = line.strip()\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rb_Q5bc6o7x"
      },
      "outputs": [],
      "source": [
        "def preprocess_txt(line):\n",
        "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
        "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
        "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
        "    return spls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmeiujjJ6o7x"
      },
      "outputs": [],
      "source": [
        "assert True\n",
        "\n",
        "# Preprocess for models fitting\n",
        "\n",
        "sentences = []\n",
        "\n",
        "morpher = MorphAnalyzer()\n",
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(string.punctuation)\n",
        "c = 0\n",
        "\n",
        "with open(\"Otvety.txt\", \"r\") as fin:\n",
        "    for line in tqdm_notebook(fin):\n",
        "        spls = preprocess_txt(line)\n",
        "        sentences.append(spls)\n",
        "        c += 1\n",
        "        if c > 100000:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_OQ8nVq6o7x"
      },
      "outputs": [],
      "source": [
        "sentences = [i for i in sentences if len(i) > 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgBlO5_p6o7x"
      },
      "outputs": [],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5itP5n4z6o7y"
      },
      "outputs": [],
      "source": [
        "modelW2V = Word2Vec(sentences=sentences, size=50, window=5, min_count=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QzmuwI26o7y"
      },
      "outputs": [],
      "source": [
        "modelFT = FastText(sentences=sentences, size=50, min_count=1, window=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi6ZRGuE6o7y"
      },
      "outputs": [],
      "source": [
        "w2v_index = annoy.AnnoyIndex(50 ,'angular')\n",
        "ft_index = annoy.AnnoyIndex(50 ,'angular')\n",
        "\n",
        "index_map = {}\n",
        "counter = 0\n",
        "\n",
        "with open(\"prepared_answers.txt\", \"r\") as f:\n",
        "    for line in tqdm_notebook(f):\n",
        "        n_w2v = 0\n",
        "        n_ft = 0\n",
        "        spls = line.split(\"\\t\")\n",
        "        index_map[counter] = spls[1]\n",
        "        question = preprocess_txt(spls[0])\n",
        "        \n",
        "        vector_w2v = np.zeros(50)\n",
        "        vector_ft = np.zeros(50)\n",
        "        for word in question:\n",
        "            if word in modelW2V:\n",
        "                vector_w2v += modelW2V[word]\n",
        "                n_w2v += 1\n",
        "            if word in modelFT:\n",
        "                vector_ft += modelFT[word]\n",
        "                n_ft += 1\n",
        "        if n_w2v > 0:\n",
        "            vector_w2v = vector_w2v / n_w2v\n",
        "        if n_ft > 0:\n",
        "            vector_ft = vector_ft / n_ft\n",
        "        w2v_index.add_item(counter, vector_w2v)\n",
        "        ft_index.add_item(counter, vector_ft)\n",
        "            \n",
        "        counter += 1\n",
        "        \n",
        "        if counter > 100000:\n",
        "            break\n",
        "\n",
        "w2v_index.build(10)\n",
        "ft_index.build(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iyoc9Din6o7y"
      },
      "outputs": [],
      "source": [
        "def get_response(question, index, model, index_map):\n",
        "    question = preprocess_txt(question)\n",
        "    vector = np.zeros(50)\n",
        "    norm = 0\n",
        "    for word in question:\n",
        "        if word in model:\n",
        "            vector += model[word]\n",
        "            norm += 1\n",
        "    if norm > 0:\n",
        "        vector = vector / norm\n",
        "    answers = index.get_nns_by_vector(vector, 3)\n",
        "    return [index_map[i] for i in answers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rxyv_Je6o7z"
      },
      "outputs": [],
      "source": [
        "TEXT = \"тапочки какого цвета\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4PF_6TU6o7z"
      },
      "outputs": [],
      "source": [
        "get_response(TEXT, w2v_index, modelW2V, index_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AB1R-UI6o7z"
      },
      "outputs": [],
      "source": [
        "get_response(TEXT, ft_index, modelFT, index_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWi2VqHI6o7z"
      },
      "outputs": [],
      "source": [
        "(12,3,9,0,)/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}