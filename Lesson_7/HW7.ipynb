{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc7fbe15",
      "metadata": {
        "id": "cc7fbe15"
      },
      "source": [
        "**Задание**\n",
        "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
        "\n",
        "1. Учим conv сеть для классификации\n",
        "\n",
        "2. Рассмотреть 2-а варианта сеточек \n",
        "\n",
        "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
        "\n",
        "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
        "\n",
        " \t\t\t\t\n",
        "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSP25Wz9tFfb",
        "outputId": "906508bb-9922-48c6-d394-797a9e7ab16f"
      },
      "id": "TSP25Wz9tFfb",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "f40c1525",
      "metadata": {
        "id": "f40c1525"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "79238f3a",
      "metadata": {
        "id": "79238f3a"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_len = 40\n",
        "num_classes = 1\n",
        "EMBEDDING_DIM = 300\n",
        "# Training\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "6398c0e4",
      "metadata": {
        "id": "6398c0e4"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('data.xls')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "cf5d8575",
      "metadata": {
        "id": "cf5d8575"
      },
      "outputs": [],
      "source": [
        "data = data[(data['Rating'] != 3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "7b151de8",
      "metadata": {
        "id": "7b151de8"
      },
      "outputs": [],
      "source": [
        "data['Rating'] = (data['Rating'] > 3).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "38da8283",
      "metadata": {
        "id": "38da8283"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['Content'], data['Rating'], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0abac8",
      "metadata": {
        "id": "4c0abac8"
      },
      "source": [
        "#### Подготовим текст, уберем стопслова, пунктуацию, приведем слова к нормальной форме."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e5daabe4",
      "metadata": {
        "id": "e5daabe4"
      },
      "outputs": [],
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "707dc18b",
      "metadata": {
        "id": "707dc18b"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "63da4974",
      "metadata": {
        "id": "63da4974"
      },
      "outputs": [],
      "source": [
        "X_test = X_test.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5948bda5",
      "metadata": {
        "id": "5948bda5"
      },
      "source": [
        "#### Соберем весть трейн сет в корпус слов (склеим все строки) и разобьем на токены."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "2f46a88a",
      "metadata": {
        "id": "2f46a88a"
      },
      "outputs": [],
      "source": [
        "train_corpus = \" \".join(X_train)\n",
        "train_corpus = train_corpus.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "f7a94c9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a94c9a",
        "outputId": "ba5b513f-427c-432a-e41e-3bbec71f8f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf59cb2",
      "metadata": {
        "id": "caf59cb2"
      },
      "source": [
        "#### Отфильтруем данные и соберём в корпус N наиболее частых токенов (параметр max_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "85695131",
      "metadata": {
        "id": "85695131"
      },
      "outputs": [],
      "source": [
        "tokens_filtered = [word for word in tokens if word.isalnum()]  # Фильтруем, чтобы не было чисел в токенах, т.к. они бесполезны"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "80d12e92",
      "metadata": {
        "id": "80d12e92"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "20342125",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20342125",
        "outputId": "a447d5dc-8187-4570-aefe-5ae894d47a4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['приложение',\n",
              " 'удобно',\n",
              " 'работать',\n",
              " 'удобный',\n",
              " 'отлично',\n",
              " 'нравиться',\n",
              " 'отличный',\n",
              " 'хороший',\n",
              " 'супер',\n",
              " 'телефон']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "tokens_filtered_top[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "b07da57c",
      "metadata": {
        "id": "b07da57c"
      },
      "outputs": [],
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()} # Делаем словарь типа слово:индекс слова"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9186374a",
      "metadata": {
        "id": "9186374a"
      },
      "source": [
        "#### Переводим текст в массив нампи, где значение ячейки = индексу слова. Длина строки - параметр max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "516b9a27",
      "metadata": {
        "id": "516b9a27"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "56eb38f8",
      "metadata": {
        "id": "56eb38f8"
      },
      "outputs": [],
      "source": [
        "X_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
        "X_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "7ee6e3be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ee6e3be",
        "outputId": "9e283382-b0a7-47a9-fc38-909ee0d434b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,  308,    1, 2206], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "X_train[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcbdd40d",
      "metadata": {
        "id": "dcbdd40d"
      },
      "source": [
        "#### Создаем модель на Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "030a7d08",
      "metadata": {
        "id": "030a7d08"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.losses import BinaryCrossentropy \n",
        "from keras.callbacks import EarlyStopping  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "3cee1a4c",
      "metadata": {
        "id": "3cee1a4c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "1d5f7250",
      "metadata": {
        "id": "1d5f7250"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "c4a921cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4a921cb",
        "outputId": "8cbfc723-6aa5-4ecd-9e74-5df90509866e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 13s 477ms/step - loss: 0.4831 - accuracy: 0.8178 - val_loss: 0.3788 - val_accuracy: 0.8573\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 11s 466ms/step - loss: 0.3226 - accuracy: 0.8674 - val_loss: 0.2447 - val_accuracy: 0.9094\n"
          ]
        }
      ],
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "66ec0c20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ec0c20",
        "outputId": "a2639702-faa9-4ae3-bb70-026824d1f87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 80ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "dcb58e7f",
      "metadata": {
        "id": "dcb58e7f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "252e6060",
      "metadata": {
        "id": "252e6060"
      },
      "outputs": [],
      "source": [
        "results_tresh = (results > 0.5) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "2bbe89fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bbe89fc",
        "outputId": "a2d053a7-a517-40da-aa75-fe6bf806cdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.59      0.65      1029\n",
            "           1       0.93      0.96      0.94      5488\n",
            "\n",
            "    accuracy                           0.90      6517\n",
            "   macro avg       0.83      0.77      0.80      6517\n",
            "weighted avg       0.90      0.90      0.90      6517\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, results_tresh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "801a98a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801a98a1",
        "outputId": "bed7b28b-5f3a-4d76-c7dd-0b7cf950cd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9406559270938696\n"
          ]
        }
      ],
      "source": [
        "print(roc_auc_score(y_test, results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba67f4a6",
      "metadata": {
        "id": "ba67f4a6"
      },
      "source": [
        "#### Вторая модель. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "003f84f1",
      "metadata": {
        "id": "003f84f1"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
        "model.add(Conv1D(256, 2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 4))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(100))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "f679f8c8",
      "metadata": {
        "id": "f679f8c8"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "560e0d14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560e0d14",
        "outputId": "ad5a2987-19ce-4aa5-909e-5e70417e6d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 26s 1s/step - loss: 0.4413 - accuracy: 0.8485 - val_loss: 0.3046 - val_accuracy: 0.8557\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.2478 - accuracy: 0.8905 - val_loss: 0.2124 - val_accuracy: 0.9086\n"
          ]
        }
      ],
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "f18a00db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f18a00db",
        "outputId": "cc4ab2ea-1f6b-4c8a-8418-77970643b46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 3s 233ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "60837bb9",
      "metadata": {
        "id": "60837bb9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "2e1b8ee6",
      "metadata": {
        "id": "2e1b8ee6"
      },
      "outputs": [],
      "source": [
        "results_tresh = (results > 0.5) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "eee9b06a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eee9b06a",
        "outputId": "4387bd1a-d340-4468-99ae-0133c8768f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.77      0.72      1029\n",
            "           1       0.96      0.93      0.94      5488\n",
            "\n",
            "    accuracy                           0.90      6517\n",
            "   macro avg       0.81      0.85      0.83      6517\n",
            "weighted avg       0.91      0.90      0.91      6517\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, results_tresh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "95916592",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95916592",
        "outputId": "9b1ecf56-56b2-4b8d-a5e5-d5c388d110a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9422779836632696\n"
          ]
        }
      ],
      "source": [
        "print(roc_auc_score(y_test, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "1e496376",
      "metadata": {
        "id": "1e496376"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8f4336c8",
      "metadata": {
        "id": "8f4336c8"
      },
      "source": [
        "#### Возьмем предобученный слой ембедингов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a8f3041",
      "metadata": {
        "id": "9a8f3041"
      },
      "source": [
        "model.txt это скаченная с https://rusvectores.org/ru/ матрица эмбедингов на русские слова. Модель обучалась с дополнительными метками частей речи, но т.к. мы изначально их не использовали, то и отсюда удалим, чтоб мы могли использовать наш предобработанный текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "79c89d4d",
      "metadata": {
        "id": "79c89d4d"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка предобученной модели\n",
        "\n",
        "!wget https://rusvectores.org/static/models/rusvectores4/taiga/taiga_upos_skipgram_300_2_2018.vec.gz\n",
        "\n",
        "!gunzip taiga_upos_skipgram_300_2_2018.vec.gz"
      ],
      "metadata": {
        "id": "mMQclfgEyr3t"
      },
      "id": "mMQclfgEyr3t",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "495c5f20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495c5f20",
        "outputId": "a68063b4-3392-45df-c99e-8a059f89407a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 209666 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "with open('taiga_upos_skipgram_300_2_2018.vec') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        word = word.split('_')[0]\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11dfc28",
      "metadata": {
        "id": "f11dfc28"
      },
      "source": [
        "#### Мы составили словарь типа слово:вектор эмбединга из файла модели. Теперь мы берем наш словарь который мы составили на основе наших текстов, и создаем матрицу весов. Т.е. берем слово в нашем словаре и по его индексу в словаре вставляем вектор эмбединга."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "3507c358",
      "metadata": {
        "id": "3507c358"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((max_words, EMBEDDING_DIM))\n",
        "for word, i in vocabulary.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "67d92ece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d92ece",
        "outputId": "27dbda4c-40f0-40f3-bf6a-ffa33ea82b67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "len(embedding_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde6d13b",
      "metadata": {
        "id": "dde6d13b"
      },
      "source": [
        "#### Теперь создаем сетку, и в качестве матрицы весов эмбединга задаем подготовленную матрицу. В первом варианте мы не будем дообучать наш эмбединг, во втором будем дообучать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "ee1b5f6c",
      "metadata": {
        "id": "ee1b5f6c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(Conv1D(256, 2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 4))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(100))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "e61f529c",
      "metadata": {
        "id": "e61f529c"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "d0dbdbfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0dbdbfa",
        "outputId": "7a554939-cfdd-488f-e0d4-68263fbf81ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 20s 758ms/step - loss: 0.4360 - accuracy: 0.8400 - val_loss: 0.2568 - val_accuracy: 0.8867\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 17s 726ms/step - loss: 0.2243 - accuracy: 0.8970 - val_loss: 0.2020 - val_accuracy: 0.9101\n"
          ]
        }
      ],
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "742e0c47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "742e0c47",
        "outputId": "0250fc25-04c9-466d-bc27-9ca83c56002c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 3s 190ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "e597487e",
      "metadata": {
        "id": "e597487e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "28f7a3af",
      "metadata": {
        "id": "28f7a3af"
      },
      "outputs": [],
      "source": [
        "results_tresh = (results > 0.5) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "63ab0259",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ab0259",
        "outputId": "2d02118e-0225-4323-9a46-2409730a073c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70      1029\n",
            "           1       0.94      0.94      0.94      5488\n",
            "\n",
            "    accuracy                           0.91      6517\n",
            "   macro avg       0.82      0.82      0.82      6517\n",
            "weighted avg       0.91      0.91      0.91      6517\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, results_tresh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "89a3a8ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89a3a8ea",
        "outputId": "e7ffbeb2-a45f-44d4-945f-c3df6526011d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9448229833374414\n"
          ]
        }
      ],
      "source": [
        "print(roc_auc_score(y_test, results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7e5724",
      "metadata": {
        "id": "9e7e5724"
      },
      "source": [
        "#### Второй вариант"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "fef253b5",
      "metadata": {
        "id": "fef253b5"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=max_len))\n",
        "model.add(Conv1D(256, 2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Conv1D(128, 4))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(100))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "11771533",
      "metadata": {
        "id": "11771533"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "e79e6b76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e79e6b76",
        "outputId": "0096a9f6-d388-45d1-cda3-4f8b1ed2c868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 26s 1s/step - loss: 0.4626 - accuracy: 0.8255 - val_loss: 0.2857 - val_accuracy: 0.8557\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 24s 1s/step - loss: 0.2324 - accuracy: 0.8913 - val_loss: 0.2025 - val_accuracy: 0.9139\n"
          ]
        }
      ],
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "9bb2629a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bb2629a",
        "outputId": "65eaaf9f-0811-4244-be87-76946e597fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 3s 236ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(X_test, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "c347fe75",
      "metadata": {
        "id": "c347fe75"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "6e465d03",
      "metadata": {
        "id": "6e465d03"
      },
      "outputs": [],
      "source": [
        "results_tresh = (results > 0.5) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "6cfb3039",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cfb3039",
        "outputId": "80b6c82d-2e03-4bf5-f5bf-d1afc0b11462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.75      0.72      1029\n",
            "           1       0.95      0.94      0.94      5488\n",
            "\n",
            "    accuracy                           0.91      6517\n",
            "   macro avg       0.82      0.84      0.83      6517\n",
            "weighted avg       0.91      0.91      0.91      6517\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, results_tresh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "014067a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "014067a3",
        "outputId": "832ada57-23b6-4349-f5dd-50b9a6e5e8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9483576854315238\n"
          ]
        }
      ],
      "source": [
        "print(roc_auc_score(y_test, results))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff1daa42",
      "metadata": {
        "id": "ff1daa42"
      },
      "source": [
        "#### В Целом если не дообучать эмбединг, то лучше результат на f1 score, да и вообще лучший результат. Если включить дообучение, то ввиду дисбаланса классов, модель работает хуже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "0d0d2196",
      "metadata": {
        "id": "0d0d2196"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}